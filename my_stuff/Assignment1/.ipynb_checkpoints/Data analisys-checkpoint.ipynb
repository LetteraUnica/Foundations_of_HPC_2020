{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extracts the master time, elapsed time and cpu percentage\n",
    "# from a serial run output file\n",
    "#\n",
    "# params:\n",
    "# moves: (int)order of magnitude of the number of moves of the file\n",
    "# path: (string)path of the text files\n",
    "#\n",
    "# return:\n",
    "# tuple of lists (master_time, elapsed_time, cpu%)\n",
    "# of all the times and cpu% found in the file\n",
    "def extract_serial_data(moves, path = \"../data/\"):\n",
    "    fname = path + \"serial.1\" + \"0\"*moves\n",
    "    f = open(fname, \"r\")\n",
    "    master_time = []\n",
    "    elapsed_time = []\n",
    "    cpu_percentage = []\n",
    "    \n",
    "    for line in f:\n",
    "        if(line.find(\"walltime\")>0):\n",
    "            master_time.append(float(line.split()[-1]))\n",
    "        if(line.find(\"elapsed\")>0):\n",
    "            split = re.split(' |elapsed |:|%CPU', line)\n",
    "            elapsed_time.append(float(split[2])*60 + float(split[3]))\n",
    "            cpu_percentage.append(float(split[4]))\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (master_time, elapsed_time, cpu_percentage)\n",
    "\n",
    "\n",
    "# Extracts the master time, elapsed time and cpu percentage\n",
    "# from a parallel run output file\n",
    "#\n",
    "# params:\n",
    "# runtype: (string)\"weak\" or \"strong\", type of the run to exctract the data\n",
    "# procs: (int)number of processors of the file\n",
    "# moves: (int)order of magnitude of the number of moves of the file\n",
    "# path: (string)path of the text files\n",
    "#\n",
    "# return:\n",
    "# tuple of lists (master_time, elapsed_time, cpu%)\n",
    "# of all the times and cpu% found in the file\n",
    "def extract_parallel_data(runtype, procs, moves, path = \"../data/\"):\n",
    "    fname = path+runtype+\".\"+str(procs)+\".1\"+\"0\"*moves\n",
    "    f = open(fname, \"r\")\n",
    "    master_time = []\n",
    "    elapsed_time = []\n",
    "    cpu_percentage = []\n",
    "    times = []\n",
    "    \n",
    "    for line in f:\n",
    "        if(line.find(\"walltime on\")>0):\n",
    "            times.append(float(line.split()[-1]))\n",
    "        if(line.find(\"elapsed\")>0):\n",
    "            split = re.split(' |elapsed |:|%CPU', line)\n",
    "            elapsed_time.append(float(split[2])*60 + float(split[3]))\n",
    "            cpu_percentage.append(float(split[4]))\n",
    "            master_time.append(max(times))\n",
    "            times = []\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return (master_time, elapsed_time, cpu_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the tuple or list data in a csv format\n",
    "def csv_print(f, data):\n",
    "    line = \"\"\n",
    "    \n",
    "    for d in data[0:-1]:\n",
    "        line = line+str(d)+\",\"\n",
    "    line = line+str(data[-1])+\"\\n\"\n",
    "    \n",
    "    f.write(line)\n",
    "\n",
    "# I create the csv files containing the runtimes of weak and strong scalability tests\n",
    "runtypes = [\"strong\", \"weak\"]\n",
    "procs = [1]\n",
    "procs.extend(list(range(4, 52, 4)))\n",
    "moves = list(range(8, 12))\n",
    "\n",
    "for run in runtypes:\n",
    "    for move in moves:\n",
    "        \n",
    "        if(move<10):\n",
    "            f = open(run+\"-scalability-10to0\"+str(move)+\".csv\", \"w\")\n",
    "        else:\n",
    "            f = open(run+\"-scalability-10to\"+str(move)+\".csv\", \"w\")\n",
    "        f.write(\"#header line: GPU processors,avg,error_bar,run1,run2,run3\\n\")\n",
    "        \n",
    "        for proc in procs:\n",
    "            # In case of weak with 1e11 moves we only have runs with 1,12,24,48 processors\n",
    "            if(run==\"weak\" and move==11 and (proc not in [1,12,24,48])):\n",
    "                continue\n",
    "            \n",
    "            master_time = extract_parallel_data(run, proc, move)[0]\n",
    "            mean = np.mean(master_time)\n",
    "            err = (max(master_time)-min(master_time))*0.5\n",
    "            master_time.insert(0, err)\n",
    "            master_time.insert(0, mean)\n",
    "            csv_print(f, master_time)\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 64, 100, 100, 100]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speedup of the sum of N numbers\n",
    "\n",
    "def Ts(N, Tread=1e-4, Tcomp=2e-9):\n",
    "    return Tread + N*Tcomp\n",
    "\n",
    "def Tp_naive(N, p, Tread=1e-4, Tcomp=2e-9, Tcomm=1e-6):\n",
    "    return Tread + 2*(p-1)*Tcomm + (N/p + p-1)*Tcomp\n",
    "\n",
    "def Tp_enhanced(N, p, Tread=1e-4, Tcomp=2e-9, Tcomm=1e-6):\n",
    "    return Tread + 2*np.ceil(np.log2(p))*Tcomm + (N/p + p-1)*Tcomp\n",
    "    \n",
    "p = np.arange(1, 101, dtype=float)\n",
    "N = np.array([2e4, 1e5, 2e5, 1e6, 2e7])\n",
    "max_speedup = []\n",
    "for n in N:\n",
    "    speedup = Ts(n)/Tp_enhanced(n, p)\n",
    "    max_speedup.append(np.argmax(speedup)+1)\n",
    "\n",
    "max_speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File of the speedup of the sum\n",
    "\n",
    "p = np.arange(1, 101, dtype=float)\n",
    "N = np.array([2e4, 1e5, 2e5, 1e6, 2e7])\n",
    "\n",
    "f = open(\"performance-model.csv\", \"w\")\n",
    "f.write(\"#header: N, best P naive algorithm , best P for enhanced algorithm\\n\")\n",
    "for n in N:\n",
    "    data = [int(n)]\n",
    "    speedup = Ts(n)/Tp_naive(n, p)\n",
    "    data.append(np.argmax(speedup)+1)\n",
    "    speedup = Ts(n)/Tp_enhanced(n, p)\n",
    "    data.append(np.argmax(speedup)+1)\n",
    "    csv_print(f, data)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the elapsed and internal time of strong scaling\n",
    "\n",
    "%matplotlib qt\n",
    "import menzalib as mz\n",
    "\n",
    "def plot_times(speedup=False, name=\"\", Ts=2.63, dTs=0.01):\n",
    "    if(speedup):\n",
    "        f = lambda x, Ts: Ts/x\n",
    "        df = lambda x, dx, Ts: mz.drapp(Ts, Ts*0.003, x, dx)\n",
    "    else:\n",
    "        f = lambda x, Ts: x\n",
    "        df = lambda x, dx, Ts: dx\n",
    "        \n",
    "    procs = [1]\n",
    "    procs.extend(list(range(4, 52, 4)))\n",
    "    moves = list(range(8, 12))\n",
    "\n",
    "    time = np.empty((len(procs), 2))\n",
    "    dtime = np.empty((len(procs), 2))\n",
    "\n",
    "    fig, axs = pl.subplots(1, 2)\n",
    "    ax1, ax2 = axs\n",
    "\n",
    "    for move in moves:\n",
    "        for (j, proc) in enumerate(procs):\n",
    "            data = extract_parallel_data(\"strong\", proc, move)[0:2]\n",
    "            time[j] = np.mean(data, 1)\n",
    "            dtime[j] = (np.max(data, 1)-np.min(data, 1))/2\n",
    "        ax1.errorbar(procs, f(time[:,0], Ts), df(time[:,0], dtime[:,0], Ts),\n",
    "                     fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "        ax2.errorbar(procs, f(time[:,1], Ts), df(time[:,1], dtime[:,1], Ts),\n",
    "                     fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "        Ts*=10\n",
    "\n",
    "    ax1.set_xscale(\"log\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.set_xlabel(\"processors P\")\n",
    "    if(speedup): ax1.set_ylabel(\"Speedup S(P)\")\n",
    "    else: ax1.set_ylabel(\"Time [s]\")\n",
    "    ax1.set_title(\"Internal time\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_xscale(\"log\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.set_xlabel(\"processors P\")\n",
    "    if(speedup): ax2.set_ylabel(\"Speedup S(P)\")\n",
    "    else: ax2.set_ylabel(\"Time [s]\")\n",
    "    ax2.set_title(\"Elapsed time\")\n",
    "    ax2.legend()\n",
    "    pl.tight_layout()\n",
    "    if(name!=\"\"):\n",
    "        pl.savefig(name, dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_times(False, \"strong_scaling_times.png\", )\n",
    "#pd.DataFrame(strong, index=moves, columns=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the strong scalability\n",
    "\n",
    "%matplotlib qt\n",
    "import menzalib as mz\n",
    "\n",
    "def plot_times(speedup=False, name=\"\"):\n",
    "    if(speedup):\n",
    "        f = lambda x, Ts: Ts/x\n",
    "        df = lambda x, dx, Ts: mz.drapp(Ts, Ts*0.003, x, dx)\n",
    "    else:\n",
    "        f = lambda x, Ts: x\n",
    "        df = lambda x, dx, Ts: dx\n",
    "        \n",
    "    procs = [1]\n",
    "    procs.extend(list(range(4, 52, 4)))\n",
    "    moves = list(range(8, 12))\n",
    "\n",
    "    time = np.empty((len(procs), 2))\n",
    "    dtime = np.empty((len(procs), 2))\n",
    "\n",
    "    fig, ax1 = pl.subplots(1, 1)\n",
    "    \n",
    "    for move in moves:\n",
    "        tmp1 = np.mean(extract_serial_data(move)[1])\n",
    "        tmp2 = np.mean(extract_parallel_data(\"strong\", 1, move)[1])\n",
    "        Ts = np.min([tmp1, tmp2])\n",
    "        \n",
    "        for (j, proc) in enumerate(procs):\n",
    "            data = extract_parallel_data(\"strong\", proc, move)[0:2]\n",
    "            time[j] = np.mean(data, 1)\n",
    "            dtime[j] = (np.max(data, 1)-np.min(data, 1))/2\n",
    "        ax1.errorbar(procs, f(time[:,1], Ts), df(time[:,1], dtime[:,1], Ts),\n",
    "                     fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "    \n",
    "    ax1.errorbar(procs, procs, fmt=\".-\", label=\"Linear scaling\")\n",
    "    ax1.set_xscale(\"log\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.set_xlabel(\"processors P\")\n",
    "    if(speedup): ax1.set_ylabel(\"Speedup S(P)\")\n",
    "    else: ax1.set_ylabel(\"Time [s]\")\n",
    "    ax1.set_title(\"Strong scaling\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    pl.tight_layout()\n",
    "    if(name!=\"\"):\n",
    "        pl.savefig(name, dpi=300)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_times(True, \"strong_scaling_speedup.png\", )\n",
    "#pd.DataFrame(strong, index=moves, columns=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 4.2430939226519335\n",
      "36 15.189453125\n",
      "48 33.203185535944904\n",
      "48 39.06597134322313\n"
     ]
    }
   ],
   "source": [
    "procs = [1]\n",
    "procs.extend(list(range(4, 52, 4)))\n",
    "moves = list(range(8, 12))\n",
    "\n",
    "speedup = np.empty(len(procs))\n",
    "\n",
    "for move in moves:\n",
    "    tmp1 = np.mean(extract_serial_data(move)[1])\n",
    "    tmp2 = np.mean(extract_parallel_data(\"strong\", 1, move)[1])\n",
    "    Ts = np.min([tmp1, tmp2])\n",
    "\n",
    "    for (j, proc) in enumerate(procs):\n",
    "        data = extract_parallel_data(\"strong\", proc, move)[1]\n",
    "        speedup[j] = Ts/np.mean(data)\n",
    "    print(procs[np.argmax(speedup)], np.max(speedup))\n",
    "\n",
    "plot_times(True, \"strong_scaling_speedup.png\", )\n",
    "#pd.DataFrame(strong, index=moves, columns=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28        0.30333333  0.34        0.39666667  0.44333333  0.50866667\n",
      "   0.57333333  0.7252381   0.78333333  0.90555556  1.036       1.15515152\n",
      "   1.31333333]\n",
      " [ 0.06        0.3525      0.32958333  0.44638889  0.46979167  0.54383333\n",
      "   0.62986111  0.83083333  0.90989583  0.98657407  1.11525     1.35416667\n",
      "   1.39659722]\n",
      " [ 1.15666667  0.4875      1.14208333  0.98472222  0.844375    1.08816667\n",
      "   1.42402778  2.07440476  2.1621875   2.16824074  3.34241667  2.35007576\n",
      "   2.38701389]\n",
      " [ 1.05333333  1.92        2.50666667  2.46888889  3.585       6.718\n",
      "   5.66111111 13.80714286 14.3925     13.87296296 13.83066667 13.10272727\n",
      "  12.25388889]]\n"
     ]
    }
   ],
   "source": [
    "# Model for the parallel overhead\n",
    "\n",
    "procs = [1]\n",
    "procs.extend(list(range(4, 52, 4)))\n",
    "moves = list(range(8, 12))\n",
    "time = np.empty((len(moves),len(procs)))\n",
    "dtime = np.empty((len(moves),len(procs)))\n",
    "\n",
    "pl.figure()\n",
    "for (i, move) in enumerate(moves):\n",
    "    Ts = np.mean(extract_serial_data(move)[1])\n",
    "    for (j, proc) in enumerate(procs):\n",
    "        data = extract_parallel_data(\"strong\", proc, move)[1]\n",
    "        time[i, j] = np.mean(data) - Ts/proc\n",
    "        dtime[i, j] = (max(data)-min(data))/2 - Ts*0.003/proc\n",
    "    dtime[-1,0] = 0.3\n",
    "    pl.errorbar(procs, time[i, :], dtime[i, :],\n",
    "                fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "\n",
    "pl.errorbar(procs, [0]*len(procs),\n",
    "            fmt=\".-\", label=\"Linear scaling\", color=\"black\")\n",
    "pl.xlabel(\"Processors P\")\n",
    "pl.ylabel(\"T overhead [s]\")\n",
    "pl.yscale(\"log\")\n",
    "pl.title(\"Parallel overhead\")\n",
    "pl.legend()\n",
    "pl.show()\n",
    "pl.tight_layout()\n",
    "pl.savefig(\"parallel_overhead_time.png\", dpi=300)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.20467865 0.03301379] [[ 9.49379775e-02 -2.36257952e-03]\n",
      " [-2.36257952e-03  6.47519979e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc699bcd5e0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def f(x, Tmpi, k):\n",
    "    return Tmpi + k*(x-1)\n",
    "\n",
    "y = time[-3, :]\n",
    "x = np.array(procs)\n",
    "dy = dtime[-3, :]\n",
    "popt, pcov = curve_fit(f, x, y, [0.3, 0.1], bounds=(0, 1))\n",
    "print(popt, pcov)\n",
    "\n",
    "pl.errorbar(x, y, dy)\n",
    "pl.plot(x, f(x, *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x, N=1e11):\n",
    "    k = 0.03\n",
    "    Tmpi = 0.28\n",
    "    return Tmpi + (x-1)*k\n",
    "\n",
    "\n",
    "y = time[-1, :]\n",
    "dy = dtime[-1, :]\n",
    "x = np.array(procs)\n",
    "pl.errorbar(x, y, dy)\n",
    "pl.plot(procs, model1(x, 1e11))\n",
    "pl.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak scaling runtime and efficency plot\n",
    "\n",
    "# Plot of the strong scalability\n",
    "\n",
    "%matplotlib qt\n",
    "import menzalib as mz\n",
    "        \n",
    "procs = [1]\n",
    "procs.extend(list(range(4, 52, 4)))\n",
    "moves = list(range(8, 12))\n",
    "\n",
    "time = np.empty(len(procs))\n",
    "dtime = np.empty(len(procs))\n",
    "\n",
    "fig, axs = pl.subplots(1, 2)\n",
    "ax1, ax2 = axs\n",
    "\n",
    "for move in moves[:-1]:\n",
    "    tmp1 = np.mean(extract_serial_data(move)[1])\n",
    "    tmp2 = np.mean(extract_parallel_data(\"strong\", 1, move)[1])\n",
    "    Ts = np.min([tmp1, tmp2])\n",
    "\n",
    "    for (j, proc) in enumerate(procs):\n",
    "        data = extract_parallel_data(\"weak\", proc, move)[1]\n",
    "        time[j] = np.mean(data)\n",
    "        dtime[j] = (np.max(data)-np.min(data))/2\n",
    "    \n",
    "    ax1.errorbar(procs, time, dtime, fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "    ax2.errorbar(procs, Ts/time, mz.drapp(Ts, 0.003*Ts, time, dtime), fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "\n",
    "weak_procs = [1,12,24,48]\n",
    "time = np.empty(len(weak_procs))\n",
    "dtime = np.empty(len(weak_procs))\n",
    "tmp1 = np.mean(extract_serial_data(11)[1])\n",
    "tmp2 = np.mean(extract_parallel_data(\"strong\", 1, 11)[1])\n",
    "Ts = np.min([tmp1, tmp2])\n",
    "for (j, proc) in enumerate(weak_procs):\n",
    "    data = extract_parallel_data(\"weak\", proc, 11)[1]\n",
    "    time[j] = np.mean(data)\n",
    "    dtime[j] = (np.max(data)-np.min(data))/2\n",
    "    \n",
    "ax1.errorbar(weak_procs, time, dtime, fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "ax2.errorbar(weak_procs, Ts/time, mz.drapp(Ts, 0.003*Ts, time, dtime), fmt=\".-\", label=\"Moves=10to\"+str(move))\n",
    "\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"processors P\")\n",
    "ax1.set_ylabel(\"Time [s]\")\n",
    "ax1.set_title(\"Weak runtime\")\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.set_xlabel(\"processors P\")\n",
    "ax2.set_ylabel(\"Efficency $\\epsilon$(P)\")\n",
    "ax2.set_ylabel(\"$T_S/T_P$\")\n",
    "ax2.set_title(\"Weak efficency\")\n",
    "ax2.legend()\n",
    "\n",
    "pl.tight_layout()\n",
    "pl.savefig(\"weak_scaling.png\", dpi=300)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
